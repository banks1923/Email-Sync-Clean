# Pipeline Integration PRD

## Project Overview
Transform the Email Sync system to route all inputs through the data pipeline stages (raw → staged → processed) instead of direct processing. Currently, services bypass the pipeline entirely - uploads go straight to processing and Gmail saves directly to the database.

## Problem Statement
- Upload commands bypass pipeline stages (direct processing)
- Gmail sync bypasses pipeline stages (direct to database) 
- No file monitoring for automatic processing
- Services don't pull work from pipeline stages
- No unified ingestion entry point

## Solution Requirements

### Core Requirements
1. **Route uploads through pipeline**: Upload commands must save files to data/raw/ first
2. **Route Gmail through pipeline**: Gmail sync must save .eml files to data/raw/
3. **File monitoring**: Automatic detection and processing of files in data/raw/
4. **Unified ingest command**: Single command to process all pending work
5. **Thread preservation**: Maintain Gmail threading information for conversation reconstruction

### File Format Strategy
- **Gmail messages**: Save .eml (backup) + .txt (processed) per message
- **PDF documents**: Process through pipeline to .txt format
- **Deduplication**: Use Message-ID as primary key, content hash as backup
- **Threading**: Preserve thread_id for conversation grouping

### Technical Specifications

#### Phase 1: Upload Pipeline Integration
- Modify tools/scripts/cli/upload_handler.py
- Import DataPipelineOrchestrator
- Change upload_pdf() to use pipeline.add_to_raw() first
- Test uploads create files in data/raw/

#### Phase 2: Gmail Pipeline Integration  
- Modify gmail/main.py sync methods
- Save .eml format to data/raw/ instead of direct DB
- Add processing: .eml → clean .txt → database
- Maintain Message-ID deduplication and thread_id preservation

#### Phase 3: File Monitoring
- Create monitoring/file_monitor.py
- Simple polling every 30 seconds
- Auto-move files: raw → staged → processed
- Handle failures by moving to quarantine/

#### Phase 4: Unified Ingest Command
- Add ingest command to tools/scripts/vsearch
- Support --all flag (process everything pending)
- Support --watch flag (start monitoring mode)
- Support --gmail flag (sync Gmail through pipeline)

#### Phase 5: Testing & Validation
- End-to-end workflow testing
- Thread reassembly validation
- Deduplication verification
- Performance testing

### Success Criteria
- All uploads go through data/raw/ → data/staged/ → data/processed/
- Gmail messages saved as .eml backups with .txt processed versions
- File monitor automatically processes new files
- Thread reconstruction works correctly
- No duplicate messages in database
- Single command processes all pending work

### Constraints
- Follow CLAUDE.md principles: simple, under 450 lines per file
- No complex enterprise patterns
- Maintain backward compatibility
- Use existing DataPipelineOrchestrator
- Maximum 30 lines per function

### Implementation Timeline
- Phase 1: 15 minutes (upload routing)
- Phase 2: 30 minutes (Gmail routing) 
- Phase 3: 30 minutes (file monitoring)
- Phase 4: 15 minutes (ingest command)
- Phase 5: 45 minutes (testing)
- Total: ~2.5 hours

## Out of Scope
- Complex materialized views
- Sharding by hash
- Multiple file formats per message
- Real-time file watching (use simple polling)
- Enterprise-scale optimizations