#!/usr/bin/env python3
"""
Database Schema Constraints Migration Script

Adds unique constraints to the documents table to prevent future duplicates
while preserving legitimate multi-chunk documents.

Safety features:
- Creates backup before changes
- Tests constraints in transaction first
- Provides rollback procedures
- Validates constraints work
"""

import sqlite3
import sys
import os
from datetime import datetime


def create_backup(db_path: str) -> str:
    """Create timestamped backup of database"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{db_path}.backup.constraints.{timestamp}"
    
    # Use SQLite backup API for proper backup
    source = sqlite3.connect(db_path)
    backup = sqlite3.connect(backup_path)
    source.backup(backup)
    source.close()
    backup.close()
    
    print(f"âœ“ Database backup created: {backup_path}")
    return backup_path


def analyze_existing_data(conn: sqlite3.Connection) -> dict:
    """Analyze current data state before applying constraints"""
    cursor = conn.cursor()
    
    # Check for potential constraint violations
    cursor.execute("""
        SELECT sha256, chunk_index, COUNT(*) as count 
        FROM documents 
        WHERE sha256 IS NOT NULL 
        GROUP BY sha256, chunk_index 
        HAVING COUNT(*) > 1
    """)
    duplicate_chunks = cursor.fetchall()
    
    cursor.execute("""
        SELECT COUNT(*) as total_docs,
               COUNT(DISTINCT sha256) as unique_sha256s,
               COUNT(DISTINCT sha256 || '-' || chunk_index) as unique_sha256_chunks
        FROM documents 
        WHERE sha256 IS NOT NULL
    """)
    stats = cursor.fetchone()
    
    cursor.execute("SELECT COUNT(*) FROM documents WHERE sha256 IS NULL")
    null_sha256_count = cursor.fetchone()[0]
    
    return {
        'duplicate_chunks': duplicate_chunks,
        'total_docs': stats[0],
        'unique_sha256s': stats[1], 
        'unique_sha256_chunks': stats[2],
        'null_sha256_count': null_sha256_count
    }


def test_constraints_dry_run(conn: sqlite3.Connection) -> bool:
    """Test constraint creation in a transaction that will be rolled back"""
    print("ğŸ§ª Testing constraint creation (dry run)...")
    
    try:
        conn.execute("BEGIN IMMEDIATE")
        
        # Test creating the unique constraint
        conn.execute("""
            CREATE UNIQUE INDEX test_documents_sha256_chunk_unique 
            ON documents(sha256, chunk_index) 
            WHERE sha256 IS NOT NULL
        """)
        
        print("âœ“ Unique constraint (sha256, chunk_index) would succeed")
        
        # Test inserting a duplicate to verify constraint works
        try:
            conn.execute("""
                INSERT INTO documents (chunk_id, sha256, chunk_index, file_name) 
                VALUES ('test_duplicate', 
                        '5e9f8884d0349a6de15a95a9a992ce28ef8534c36eb86c42ce68ec8978fe047a', 
                        0, 'test_file.pdf')
            """)
            print("âš ï¸ WARNING: Test duplicate insert succeeded - constraint not working")
            return False
        except sqlite3.IntegrityError:
            print("âœ“ Constraint correctly prevents duplicate (sha256, chunk_index)")
        
        conn.execute("ROLLBACK")
        return True
        
    except Exception as e:
        conn.execute("ROLLBACK")
        print(f"âœ— Dry run failed: {e}")
        return False


def apply_constraints(conn: sqlite3.Connection) -> bool:
    """Apply the unique constraints to the documents table"""
    print("ğŸ“ Applying database constraints...")
    
    try:
        conn.execute("BEGIN IMMEDIATE")
        
        # Create unique constraint on (sha256, chunk_index) for non-null SHA256s
        # This allows legitimate multi-chunk documents while preventing true duplicates
        conn.execute("""
            CREATE UNIQUE INDEX idx_documents_sha256_chunk_unique 
            ON documents(sha256, chunk_index) 
            WHERE sha256 IS NOT NULL
        """)
        print("âœ“ Created unique index: idx_documents_sha256_chunk_unique")
        
        # Also create a simple sha256 index if it doesn't exist (for queries)
        try:
            conn.execute("CREATE INDEX IF NOT EXISTS idx_documents_sha256 ON documents(sha256)")
            print("âœ“ Ensured SHA256 index exists")
        except sqlite3.OperationalError:
            # Index already exists
            pass
        
        conn.execute("COMMIT")
        print("âœ“ Constraints applied successfully")
        return True
        
    except Exception as e:
        conn.execute("ROLLBACK")
        print(f"âœ— Failed to apply constraints: {e}")
        return False


def validate_constraints(conn: sqlite3.Connection) -> bool:
    """Validate that constraints are working properly"""
    print("ğŸ” Validating constraints...")
    
    # Test 1: Try to insert a duplicate (sha256, chunk_index)
    try:
        conn.execute("""
            INSERT INTO documents (chunk_id, sha256, chunk_index, file_name) 
            VALUES ('validation_test_duplicate', 
                    '5e9f8884d0349a6de15a95a9a992ce28ef8534c36eb86c42ce68ec8978fe047a', 
                    0, 'test_validation.pdf')
        """)
        print("âœ— VALIDATION FAILED: Duplicate (sha256, chunk_index) was allowed")
        return False
    except sqlite3.IntegrityError as e:
        if "UNIQUE constraint failed" in str(e):
            print("âœ“ Constraint correctly prevents duplicate (sha256, chunk_index)")
        else:
            print(f"âœ— Unexpected integrity error: {e}")
            return False
    
    # Test 2: Verify we can still insert different chunk_index for same sha256
    try:
        conn.execute("""
            INSERT INTO documents (chunk_id, sha256, chunk_index, file_name) 
            VALUES ('validation_test_different_chunk', 
                    '5e9f8884d0349a6de15a95a9a992ce28ef8534c36eb86c42ce68ec8978fe047a', 
                    99, 'test_validation_chunk99.pdf')
        """)
        print("âœ“ Different chunk_index for same SHA256 allowed correctly")
        
        # Clean up test record
        conn.execute("DELETE FROM documents WHERE chunk_id = 'validation_test_different_chunk'")
        
    except Exception as e:
        print(f"âœ— VALIDATION FAILED: Could not insert different chunk_index: {e}")
        return False
    
    # Test 3: Verify NULL sha256 is still allowed (multiple times)
    try:
        conn.execute("""
            INSERT INTO documents (chunk_id, sha256, chunk_index, file_name) 
            VALUES ('validation_test_null1', NULL, 0, 'test_null1.pdf')
        """)
        conn.execute("""
            INSERT INTO documents (chunk_id, sha256, chunk_index, file_name) 
            VALUES ('validation_test_null2', NULL, 0, 'test_null2.pdf')
        """)
        print("âœ“ Multiple NULL SHA256 values allowed correctly")
        
        # Clean up test records
        conn.execute("DELETE FROM documents WHERE chunk_id LIKE 'validation_test_null%'")
        
    except Exception as e:
        print(f"âœ— VALIDATION FAILED: NULL SHA256 handling broken: {e}")
        return False
    
    print("âœ… All constraint validations passed")
    return True


def show_rollback_instructions(backup_path: str, db_path: str):
    """Show instructions for rolling back changes"""
    print("\nğŸ“‹ ROLLBACK INSTRUCTIONS:")
    print("If you need to roll back these changes:")
    print("1. Stop all applications using the database")
    print("2. Replace current database:")
    print(f"   cp {backup_path} {db_path}")
    print("3. Restart applications")
    print(f"\nBackup location: {backup_path}")


def main():
    """Main migration function"""
    db_path = "data/emails.db"
    
    if not os.path.exists(db_path):
        print(f"âœ— Database not found: {db_path}")
        sys.exit(1)
    
    print("ğŸ“Š Email Sync Database Constraints Migration")
    print("=" * 50)
    
    # Step 1: Create backup
    backup_path = create_backup(db_path)
    
    # Step 2: Analyze current data
    conn = sqlite3.connect(db_path)
    analysis = analyze_existing_data(conn)
    
    print("\nğŸ“ˆ Current Database State:")
    print(f"Total documents: {analysis['total_docs']}")
    print(f"Unique SHA256s: {analysis['unique_sha256s']}")
    print(f"Unique (SHA256, chunk_index): {analysis['unique_sha256_chunks']}")
    print(f"NULL SHA256s: {analysis['null_sha256_count']}")
    
    if analysis['duplicate_chunks']:
        print(f"\nâš ï¸  Found {len(analysis['duplicate_chunks'])} duplicate (sha256, chunk_index) pairs:")
        for sha256, chunk_index, count in analysis['duplicate_chunks']:
            print(f"  SHA256: {sha256[:16]}... chunk_index: {chunk_index} (count: {count})")
        print("\nâŒ Cannot proceed with duplicates present!")
        print("Please resolve duplicates manually first.")
        conn.close()
        sys.exit(1)
    else:
        print("âœ“ No duplicate (SHA256, chunk_index) pairs found")
    
    # Step 3: Test constraints (dry run)
    if not test_constraints_dry_run(conn):
        print("\nâŒ Dry run failed - aborting migration")
        conn.close()
        sys.exit(1)
    
    # Step 4: Apply constraints
    if not apply_constraints(conn):
        print("\nâŒ Failed to apply constraints")
        conn.close()
        sys.exit(1)
    
    # Step 5: Validate constraints
    if not validate_constraints(conn):
        print("\nâŒ Constraint validation failed")
        conn.close()
        sys.exit(1)
    
    conn.close()
    
    # Step 6: Show summary
    print("\nğŸ‰ Migration completed successfully!")
    print("\nğŸ“Š Applied Changes:")
    print("âœ“ Added unique constraint: idx_documents_sha256_chunk_unique")
    print("âœ“ Ensured SHA256 index exists for query performance") 
    print("âœ“ Validated constraints prevent duplicates")
    print("âœ“ Confirmed multi-chunk documents still work")
    
    show_rollback_instructions(backup_path, db_path)
    
    print("\nğŸ”’ Database Integrity Status:")
    print("âœ… Documents table now prevents duplicate (SHA256, chunk_index)")
    print("âœ… Content_unified table has UNIQUE(source_type, source_id)")
    print("âœ… Embeddings table has UNIQUE(content_id, model)")
    print("âœ… Full pipeline protected against data duplication")


if __name__ == "__main__":
    main()