#!/usr/bin/env python3
"""
Enhanced OCR Coordinator - Quality-Gated Processing Pipeline

Implements the comprehensive OCR overhaul plan with:
- Quality-gated processing pipeline with fail-fast
- Born-digital fast-path detection
- Dual-pass OCR processing
- Integration with content quality scoring
- Structured error handling and retry logic

Architecture: Wraps existing OCRCoordinator with quality gates and enhanced processing
"""

import time
import uuid
from typing import Dict, Any, List
from datetime import datetime
from loguru import logger

from .ocr_coordinator import OCRCoordinator
from .enhanced_ocr_engine import EnhancedOCREngine
from .loader import PDFLoader
from .validator import PDFValidator
from .rasterizer import PDFRasterizer
import sys
import os
# Add project root to path for imports  
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from shared.content_quality_scorer import ContentQualityScorer, ValidationStatus


class EnhancedOCRCoordinator:
    """
    Enhanced OCR coordinator with quality gates and dual-pass processing.
    
    Features:
    - Quality-gated pipeline with fail-fast at each stage
    - Born-digital fast-path for text-based PDFs
    - Dual-pass OCR (standard -> enhanced)
    - Structured error handling and retry logic
    - Comprehensive quality metrics and diagnostics
    - Integration with content quality scoring system
    """
    
    def __init__(self, dpi: int = 300):
        # Core components
        self.loader = PDFLoader()
        self.validator = PDFValidator()
        self.rasterizer = PDFRasterizer(dpi=dpi)
        self.enhanced_engine = EnhancedOCREngine(dpi=dpi)
        self.quality_scorer = ContentQualityScorer()
        
        # Legacy coordinator for fallback
        self.legacy_coordinator = OCRCoordinator(dpi=dpi)
        
        # Processing configuration
        self.processing_config = {
            'max_processing_time': 300,  # 5 minutes max per PDF
            'min_confidence_threshold': 0.3,  # Minimum OCR confidence
            'enable_born_digital_bypass': True,
            'enable_dual_pass': True,
            'fail_fast_on_quality_gates': True,
        }
        
        # Pipeline run tracking
        self.pipeline_run_id = None
    
    def process_pdf_with_enhanced_ocr(
        self, 
        pdf_path: str, 
        force_ocr: bool = False,
        quality_gates_enabled: bool = True
    ) -> dict[str, Any]:
        """
        Main enhanced OCR processing with quality gates and fail-fast.
        
        Args:
            pdf_path: Path to PDF file
            force_ocr: Force OCR even for text PDFs
            quality_gates_enabled: Enable quality validation gates
            
        Returns:
            Dict with extracted text, quality metrics, and processing metadata
        """
        # Initialize pipeline run
        self.pipeline_run_id = str(uuid.uuid4())[:8]
        start_time = time.time()
        
        processing_stages = []
        pipeline_metadata = {
            'pipeline_run_id': self.pipeline_run_id,
            'started_at': datetime.now().isoformat(),
            'pdf_path': pdf_path,
            'force_ocr': force_ocr,
            'quality_gates_enabled': quality_gates_enabled
        }
        
        try:
            logger.info(f"üî¨ Enhanced OCR pipeline started (run: {self.pipeline_run_id})")
            
            # Stage 1: File validation (fail-fast)
            logger.info("‚Üí Stage 1: File validation")
            validation = self.loader.validate_pdf_file(pdf_path)
            processing_stages.append({
                'stage': 'file_validation',
                'success': validation['success'],
                'duration': time.time() - start_time,
                'details': validation
            })
            
            if not validation['success']:
                return self._build_failure_result(
                    'file_validation_failed', 
                    validation.get('error', 'File validation failed'),
                    pipeline_metadata,
                    processing_stages
                )
            
            # Stage 2: OCR necessity check (with born-digital detection)
            logger.info("‚Üí Stage 2: OCR necessity analysis")
            stage_start = time.time()
            
            ocr_check = self.validator.should_use_ocr(pdf_path, force_ocr)
            processing_stages.append({
                'stage': 'ocr_necessity_check',
                'success': ocr_check['success'],
                'duration': time.time() - stage_start,
                'details': ocr_check
            })
            
            if not ocr_check['success']:
                return self._build_failure_result(
                    'ocr_check_failed',
                    ocr_check.get('error', 'OCR necessity check failed'),
                    pipeline_metadata,
                    processing_stages
                )
            
            # Fast-path for text-based PDFs
            if not ocr_check['use_ocr'] and not force_ocr:
                logger.info("‚úì Born-digital fast-path: using text extraction")
                return {
                    'success': True,
                    'method': 'text_extraction',
                    'text': '',  # Signal to caller to use PyPDF2
                    'ocr_used': False,
                    'validation_status': ValidationStatus.TEXT_VALIDATED.value,
                    'pipeline_metadata': pipeline_metadata,
                    'processing_stages': processing_stages,
                    'processing_time': time.time() - start_time
                }
            
            # Stage 3: PDF rasterization (fail-fast)
            logger.info("‚Üí Stage 3: PDF rasterization")
            stage_start = time.time()
            
            raster_result = self.rasterizer.convert_pdf_to_images(pdf_path)
            processing_stages.append({
                'stage': 'pdf_rasterization',
                'success': raster_result['success'],
                'duration': time.time() - stage_start,
                'details': {'image_count': len(raster_result.get('images', []))}
            })
            
            if not raster_result['success']:
                return self._build_failure_result(
                    'rasterization_failed',
                    raster_result.get('error', 'PDF rasterization failed'),
                    pipeline_metadata,
                    processing_stages
                )
            
            images = raster_result['images']
            logger.info(f"  ‚úì Rasterized {len(images)} pages")
            
            # Stage 4: Enhanced OCR processing (with quality gates)
            logger.info("‚Üí Stage 4: Enhanced OCR processing")
            stage_start = time.time()
            
            ocr_results = self._process_pages_with_enhanced_ocr(
                images, 
                quality_gates_enabled
            )
            
            processing_stages.append({
                'stage': 'enhanced_ocr',
                'success': ocr_results['success'],
                'duration': time.time() - stage_start,
                'details': {
                    'pages_processed': ocr_results.get('pages_processed', 0),
                    'average_confidence': ocr_results.get('average_confidence', 0),
                    'processing_method': ocr_results.get('processing_method', 'unknown')
                }
            })
            
            if not ocr_results['success']:
                return self._build_failure_result(
                    'enhanced_ocr_failed',
                    ocr_results.get('error', 'Enhanced OCR processing failed'),
                    pipeline_metadata,
                    processing_stages
                )
            
            # Stage 5: Quality validation and final assessment
            logger.info("‚Üí Stage 5: Quality validation")
            stage_start = time.time()
            
            final_validation = self._perform_final_quality_validation(
                ocr_results['text'],
                len(images),
                ocr_results.get('quality_metrics')
            )
            
            processing_stages.append({
                'stage': 'quality_validation',
                'success': final_validation['success'],
                'duration': time.time() - stage_start,
                'details': final_validation
            })
            
            # Build final result
            total_time = time.time() - start_time
            pipeline_metadata['completed_at'] = datetime.now().isoformat()
            pipeline_metadata['total_duration'] = total_time
            
            final_result = {
                'success': True,
                'method': 'enhanced_ocr',
                'text': ocr_results['text'],
                'ocr_used': True,
                'page_count': len(images),
                'confidence': ocr_results.get('average_confidence', 0),
                'validation_status': final_validation['validation_status'],
                'quality_score': final_validation.get('quality_score', 0),
                'quality_metrics': final_validation.get('quality_metrics'),
                'pipeline_metadata': pipeline_metadata,
                'processing_stages': processing_stages,
                'processing_time': total_time,
                'processing_log': ocr_results.get('processing_log', [])
            }
            
            logger.info(f"‚úÖ Enhanced OCR pipeline completed in {total_time:.1f}s "
                       f"(status: {final_validation['validation_status']})")
            
            return final_result
            
        except Exception as e:
            logger.error(f"‚ùå Enhanced OCR pipeline failed: {e}")
            return self._build_failure_result(
                'pipeline_exception',
                str(e),
                pipeline_metadata,
                processing_stages,
                exception=e
            )
    
    def _process_pages_with_enhanced_ocr(
        self, 
        images: list, 
        quality_gates_enabled: bool
    ) -> dict[str, Any]:
        """
        Process all pages with enhanced dual-pass OCR.
        """
        page_results = []
        page_texts = []
        confidences = []
        processing_logs = []
        
        try:
            for i, image in enumerate(images):
                logger.info(f"  Processing page {i+1}/{len(images)}")
                
                # Use enhanced dual-pass OCR
                page_result = self.enhanced_engine.extract_text_with_dual_pass(
                    image,
                    page_count=len(images)
                )
                
                page_results.append(page_result)
                
                if page_result['success']:
                    page_texts.append(page_result['text'])
                    confidences.append(page_result.get('confidence', 0))
                    
                    if 'processing_log' in page_result:
                        processing_logs.extend(page_result['processing_log'])
                else:
                    page_texts.append('')
                    confidences.append(0)
                    logger.warning(f"  ‚ö† Page {i+1} OCR failed: {page_result.get('error', 'Unknown error')}")
            
            # Combine page results
            combined_text = '\n\n'.join(filter(None, page_texts))  # Filter out empty pages
            average_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            # Determine processing method used
            methods_used = set()
            for result in page_results:
                if result['success']:
                    methods_used.add(result.get('method', 'unknown'))
            
            processing_method = 'mixed' if len(methods_used) > 1 else next(iter(methods_used), 'unknown')
            
            return {
                'success': True,
                'text': combined_text,
                'pages_processed': len(page_results),
                'successful_pages': sum(1 for r in page_results if r['success']),
                'average_confidence': average_confidence,
                'processing_method': processing_method,
                'processing_log': processing_logs,
                'page_results': page_results  # For debugging
            }
            
        except Exception as e:
            logger.error(f"Page processing failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'pages_processed': len(page_results)
            }
    
    def _perform_final_quality_validation(
        self,
        text: str,
        page_count: int,
        existing_metrics: Any = None
    ) -> dict[str, Any]:
        """
        Perform final quality validation using ContentQualityScorer.
        """
        try:
            if existing_metrics:
                # Use existing metrics if available
                quality_metrics = existing_metrics
            else:
                # Score the content
                quality_metrics = self.quality_scorer.score_content(text, page_count)
            
            validation_status = quality_metrics.validation_status.value
            quality_score = quality_metrics.quality_score
            
            # Log quality assessment
            if quality_metrics.failure_reasons:
                logger.warning(f"  Quality issues: {quality_metrics.failure_reasons}")
            
            return {
                'success': True,
                'validation_status': validation_status,
                'quality_score': quality_score,
                'quality_metrics': quality_metrics,
                'passed_quality_gates': validation_status in [
                    ValidationStatus.TEXT_VALIDATED.value,
                    ValidationStatus.ENTITIES_EXTRACTED.value
                ]
            }
            
        except Exception as e:
            logger.error(f"Quality validation failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'validation_status': ValidationStatus.OCR_DONE.value
            }
    
    def _build_failure_result(
        self,
        failure_type: str,
        error_message: str,
        pipeline_metadata: dict[str, Any],
        processing_stages: list[dict[str, Any]],
        exception: Exception = None
    ) -> dict[str, Any]:
        """
        Build standardized failure result with diagnostics.
        """
        pipeline_metadata['failed_at'] = datetime.now().isoformat()
        pipeline_metadata['failure_type'] = failure_type
        
        failure_result = {
            'success': False,
            'error': error_message,
            'failure_type': failure_type,
            'validation_status': ValidationStatus.OCR_DONE.value,
            'pipeline_metadata': pipeline_metadata,
            'processing_stages': processing_stages,
            'processing_time': time.time() - pipeline_metadata.get('started_timestamp', time.time())
        }
        
        if exception:
            failure_result['exception_type'] = type(exception).__name__
        
        logger.error(f"‚ùå Pipeline failure ({failure_type}): {error_message}")
        return failure_result
    
    def validate_enhanced_setup(self) -> dict[str, Any]:
        """
        Validate complete enhanced OCR setup.
        """
        base_validation = self.legacy_coordinator.validate_setup()
        enhanced_validation = self.enhanced_engine.validate_enhanced_setup()
        quality_scorer_validation = {'available': True, 'version': 'v1.0'}
        
        return {
            'base_coordinator': base_validation,
            'enhanced_engine': enhanced_validation,
            'quality_scorer': quality_scorer_validation,
            'processing_config': self.processing_config,
            'ready': (
                base_validation.get('ready', False) and
                enhanced_validation.get('ready', False)
            )
        }
    
    def get_processing_statistics(self) -> dict[str, Any]:
        """
        Get processing statistics for monitoring and diagnostics.
        """
        # This would typically query a database of processing runs
        # For now, return configuration info
        return {
            'configuration': self.processing_config,
            'capabilities': {
                'born_digital_detection': True,
                'dual_pass_ocr': True,
                'quality_gates': True,
                'structured_error_handling': True,
                'comprehensive_diagnostics': True
            },
            'current_pipeline_run': self.pipeline_run_id
        }


def get_enhanced_ocr_coordinator(dpi: int = 300) -> EnhancedOCRCoordinator:
    """Factory function for enhanced OCR coordinator."""
    return EnhancedOCRCoordinator(dpi=dpi)